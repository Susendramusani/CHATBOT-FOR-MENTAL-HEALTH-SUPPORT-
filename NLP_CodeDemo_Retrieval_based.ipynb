{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "-DjieXLqVq7J"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Embedding, Dense, Flatten, Conv1D, MaxPooling1D, SimpleRNN, GRU, LSTM, Input,\n",
    "                                      TimeDistributed, Dropout, Bidirectional)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1Gx2VoOAV_vM",
    "outputId": "8abdcd76-5afd-426a-b1d7-7596134b7208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload the 'requirements.txt' file.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7e7c0bb5-01b5-407d-8280-6da6a41445dd\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7e7c0bb5-01b5-407d-8280-6da6a41445dd\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving requirements.txt to requirements (4).txt\n",
      "Collecting absl-py==2.1.0 (from -r requirements (4).txt (line 1))\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 2)) (1.6.3)\n",
      "Collecting cachetools==5.3.2 (from -r requirements (4).txt (line 3))\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting certifi==2023.11.17 (from -r requirements (4).txt (line 4))\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from -r requirements (4).txt (line 5))\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 6)) (8.1.7)\n",
      "Collecting contourpy==1.1.1 (from -r requirements (4).txt (line 7))\n",
      "  Using cached contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 8)) (0.12.1)\n",
      "Collecting flatbuffers==23.5.26 (from -r requirements (4).txt (line 9))\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting fonttools==4.47.2 (from -r requirements (4).txt (line 10))\n",
      "  Using cached fonttools-4.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (157 kB)\n",
      "Collecting gast==0.4.0 (from -r requirements (4).txt (line 11))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 12)) (2.27.0)\n",
      "Collecting google-auth-oauthlib==1.0.0 (from -r requirements (4).txt (line 13))\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 14)) (0.2.0)\n",
      "Collecting grpcio==1.60.0 (from -r requirements (4).txt (line 15))\n",
      "  Using cached grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting h5py==3.10.0 (from -r requirements (4).txt (line 16))\n",
      "  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting idna==3.6 (from -r requirements (4).txt (line 17))\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting importlib-resources==6.1.1 (from -r requirements (4).txt (line 18))\n",
      "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting joblib==1.3.2 (from -r requirements (4).txt (line 19))\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting keras==2.13.1 (from -r requirements (4).txt (line 20))\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting kiwisolver==1.4.5 (from -r requirements (4).txt (line 21))\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting libclang==16.0.6 (from -r requirements (4).txt (line 22))\n",
      "  Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting Markdown==3.5.2 (from -r requirements (4).txt (line 23))\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting MarkupSafe==2.1.4 (from -r requirements (4).txt (line 24))\n",
      "  Using cached MarkupSafe-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting matplotlib==3.7.4 (from -r requirements (4).txt (line 25))\n",
      "  Using cached matplotlib-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting nltk==3.8.1 (from -r requirements (4).txt (line 26))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy==1.24.3 (from -r requirements (4).txt (line 27))\n",
      "  Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 28)) (3.2.2)\n",
      "Collecting opt-einsum==3.3.0 (from -r requirements (4).txt (line 29))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pandas==2.0.3 (from -r requirements (4).txt (line 30))\n",
      "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting pillow==10.2.0 (from -r requirements (4).txt (line 31))\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting protobuf==4.25.2 (from -r requirements (4).txt (line 32))\n",
      "  Using cached protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting pyasn1==0.5.1 (from -r requirements (4).txt (line 33))\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules==0.3.0 (from -r requirements (4).txt (line 34))\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pyparsing==3.1.1 (from -r requirements (4).txt (line 35))\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pytz==2023.3.post1 (from -r requirements (4).txt (line 36))\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting regex==2023.12.25 (from -r requirements (4).txt (line 37))\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.31.0 (from -r requirements (4).txt (line 38))\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 39)) (1.3.1)\n",
      "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 40)) (4.9)\n",
      "Collecting tensorboard==2.13.0 (from -r requirements (4).txt (line 41))\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements (4).txt (line 42)) (0.7.2)\n",
      "Collecting tensorflow==2.13.0 (from -r requirements (4).txt (line 43))\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting tensorflow-estimator==2.13.0 (from -r requirements (4).txt (line 44))\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-macos==2.13.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-macos==2.13.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies\n",
    "from google.colab import files\n",
    "\n",
    "# Upload the requirements.txt file\n",
    "print(\"Please upload the 'requirements.txt' file.\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Install dependencies from the uploaded requirements file\n",
    "for file_name in uploaded.keys():\n",
    "    if file_name.endswith('.txt'):\n",
    "        !pip install -r \"{file_name}\"\n",
    "\n",
    "# Ensure NLTK resources are available\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "UEY13wFCWCKi",
    "outputId": "9343085f-a194-4c58-f66c-221b317d0c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload the dataset file. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f13d0aad-b8d4-4501-bbc5-4f5f442eab4b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-f13d0aad-b8d4-4501-bbc5-4f5f442eab4b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving mentalhealth.csv to mentalhealth (3).csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"Question_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2707777,\n        \"min\": 1030153,\n        \"max\": 9679704,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1043721,\n          4134858,\n          7807643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"I received a diagnosis but I don\\u2019t think it\\u2019s right. What can I do?\",\n          \"How can I manage grief?\",\n          \"If cannabis is dangerous, why are we legalizing it?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"If possible, bring up your concerns with the professional who provided the diagnosis. That way, the professional can answer your questions and you can better understand their decision. \\n If that doesn\\u2019t resolve the situation or a follow-up appointment isn\\u2019t possible, you can ask for a second opinion. A second opinion is an assessment from a different professional. This can give you better understanding of what\\u2019s going on and what to do about it. Second opinions are common when it comes to major health decisions\\u2014you won\\u2019t hurt anyone\\u2019s feelings and your doctor will try to accommodate reasonable requests for a second opinion. Talk to your family doctor (or go to a walk-in clinic) to discuss your options and get a referral to a different program or health professional, if needed. \\n For more how to get a second opinion, see HealthLinkBC\\u2019s factsheet at www.healthlinkbc.ca. \\n For general tips on managing a diagnosis of a mental illness and working well with health care professionals, see HeretoHelp\\u2019s Managing a Mental Illness series.\",\n          \"While a lot of people think of grief in terms of losing a person or pet, grief can come up whenever you lose something important. This includes: \\n Losing security, like losing your job or wondering how long you'll be able to pay rent \\n Losing stability or routine, like finding yourself working from home or navigating childcare closures \\n Losing your sense of safety, like fearing you or someone you love might end up with COVID-19 \\n Losing your social relationships, like missing time with family and friends now that everyone must practice physical distancing or self-isolation \\n Losing hope for the future, like feeling that life will never go back to normal \\n Losing important goals, like finding your classes, sports competitions, or performances are cancelled for the foreseeable future \\n Losing important milestone celebrations like graduation ceremonies and weddings \\n Grief bring up complicated feelings. You might feel sad, angry, frustrated, fearful, or hopeless. You may have a hard time eating or sleeping, or feel very tense. You may feel overwhelmed and tired. You may wonder if life will ever feel normal again. \\n Everyone grieves in their own way and their own time. Here are some strategies to try as you navigate your own journey. \\n Acknowledge and express your feelings in a healthy way. Give your feelings a name and find healthy ways to express them, such as by talking with a friend, writing in a journal, or making art. \\n Give yourself as much time as you need. Grief follows its own schedule. Give yourself permission to use this time to take care of your well-being. Let go of expectations, tasks, or other obligations that can wait. \\n Seek support. Grief can feel very isolating, even though a lot of people are experiencing some sort of loss right now. Reach out to friends or family and share your feelings. Look for ways to help and support each other. \\n Take care of yourself. Ignoring health and well-being can make difficult experiences feel worse. Eat as well as you can, try to get enough sleep, spend time outside if it's safe for you to do so, and exercise regularly. Think about self-care activities or strategies that have helped you cope with challenging situations in the past and make time for those activities. \\n Know that feelings of grief will pass. Grief may feel intense at times, but those feelings will become more manageable over time and will eventually pass. \\n Connect with a mental health professional if you're having a hard time. If you're having a hard time getting through the day, coping in unhealthy ways, or having a hard time managing difficult thoughts or feelings, it's a good idea to seek help from a professional like a psychologist or counsellor\\u2014many now offer online or phone appointments. To find help: \\n For everyone \\n BC Psychological Association: Find a Registered Psychologist at www.psychologists.bc.ca/find_psychologist \\n BC Association of Clinical Counsellors: Find a Registered Clinical Counsellor at bc-counsellors.org \\n BC Mental Health Support Line: call 310-6789 (no area code) for to learn about services in your area or just to talk with someone right now \\n For young people \\n Kids Help Phone: Talk to a counsellor at 1-800-668-6868 or chat at kidshelpphone.ca (available 24/7) \\n Foundry: Contact your local Foundry office at foundrybc.ca for Foundy Virtual and information about local resources (for youth ages 12-24) \\n Youth in BC: Chat with a crisis line responder at youthinbc.com (available every day from noon \\u2013 1:00am) \\n That Discomfort You're Feeling Is Grief in Harvard Business Review at hbr.org/2020/03/that-discomfort-youre-feeling-is-grief \\n Grieving from the Canadian Mental Health Association at cmha.ca/documents/grieving \\n Coping with Grief and Loss from Mind Your Mind at mindyourmind.ca/wellness/coping-grief-and-loss\",\n          \"Cannabis smoke, for example, contains cancer-causing toxins. However, the risk of developing some cancers (e.g., mouth, tongue and lung) is less for cannabis smokers than tobacco smokers, partly because they tend to smoke less than tobacco users. And, while all drugs have an effect on the brain, the particular properties of the drug influence the level of risk of harmful consequences. The negative effects of cannabis on the brain, for example, seem to be less than the effects of some substances such as alcohol. \\n Legalizing cannabis provides an opportunity to put in place regulations to minimize potential harms. The danger of buying and using any illegal drug is that we can never know for sure what exactly is in it. Cannabis is legal in Canada as of October 17, 2018. Adults (over age 19 in BC) are now permitted to possess up to 30 grams of cannabis in public. Cannabis is regulated by the Province of British Columbia and will be sold through the Liquor Distribution Branch. Cannabis will be tested for quality. \\n When drugs are produced and obtained inside a regulated system, it is possible for us to know about the contents and dosage of what we are taking. This helps us manage the risks. However, it is likely that cannabis will still be available outside the government system. It is important to know that the quality of cannabis obtained from a dealer or a friend is unknown and may contain contaminants like mold, mildew, or fillers that may be toxic. \\n The legalization of cannabis also provides us with openings to engage in honest and thoughtful discussions about drug use with our families and communities. When dealing with complex issues, like cannabis policy, no one has all the answers. But as community members, we all have thoughts, feelings and experiences around drugs and drug use to share with each other. Engaging together to explore and share ideas will help us discover how to manage use, as individuals and communities, in ways that maximize benefit and minimize harm. \\n The Canadian Institute for Substance Use Research, formerly CARBC, is a member of the BC Partners for Mental Health and Addictions Information. The institute is dedicated to the study of substance use in support of community-wide efforts aimed at providing all people with access to healthier lives, whether using substances or not. For more, visit www.cisur.ca.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-87363c1e-8258-4b5a-bf30-1d616e301a36\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1590140</td>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>Mental illnesses are health conditions that di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2110618</td>\n",
       "      <td>Who does mental illness affect?</td>\n",
       "      <td>Mental illness does can affect anyone, regardl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9434130</td>\n",
       "      <td>What are some of the warning signs of mental i...</td>\n",
       "      <td>Symptoms of mental health disorders vary depen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7657263</td>\n",
       "      <td>Can people with mental illness recover?</td>\n",
       "      <td>When healing from mental illness, early identi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619387</td>\n",
       "      <td>What should I do if I know someone who appears...</td>\n",
       "      <td>We encourage those with symptoms to talk to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87363c1e-8258-4b5a-bf30-1d616e301a36')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-87363c1e-8258-4b5a-bf30-1d616e301a36 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-87363c1e-8258-4b5a-bf30-1d616e301a36');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-1c17af21-807c-4ffd-a819-68f52d0bd6fe\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c17af21-807c-4ffd-a819-68f52d0bd6fe')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-1c17af21-807c-4ffd-a819-68f52d0bd6fe button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Question_ID                                          Questions  \\\n",
       "0      1590140        What does it mean to have a mental illness?   \n",
       "1      2110618                    Who does mental illness affect?   \n",
       "2      9434130  What are some of the warning signs of mental i...   \n",
       "3      7657263            Can people with mental illness recover?   \n",
       "4      1619387  What should I do if I know someone who appears...   \n",
       "\n",
       "                                             Answers  \n",
       "0  Mental illnesses are health conditions that di...  \n",
       "1  Mental illness does can affect anyone, regardl...  \n",
       "2  Symptoms of mental health disorders vary depen...  \n",
       "3  When healing from mental illness, early identi...  \n",
       "4  We encourage those with symptoms to talk to th...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload dataset\n",
    "print(\"Please upload the dataset file. \")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "for file_name in uploaded.keys():\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(file_name)\n",
    "    elif file_name.endswith('.json'):\n",
    "        with open(file_name, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            df = pd.DataFrame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UVUrXPdWEhN",
    "outputId": "bb5fde29-2bd5-48be-be11-f85e4276c967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Questions Column:\n",
      "                                           Questions  \\\n",
      "0        What does it mean to have a mental illness?   \n",
      "1                    Who does mental illness affect?   \n",
      "2  What are some of the warning signs of mental i...   \n",
      "3            Can people with mental illness recover?   \n",
      "4  What should I do if I know someone who appears...   \n",
      "\n",
      "                                   cleaned_questions  \n",
      "0         what does it mean to have a mental illness  \n",
      "1                     who does mental illness affect  \n",
      "2  what are some of the warning signs of mental i...  \n",
      "3             can people with mental illness recover  \n",
      "4  what should i do if i know someone who appears...  \n"
     ]
    }
   ],
   "source": [
    "# Dynamically check for the correct column name\n",
    "if 'Questions' in df.columns:\n",
    "    df['cleaned_questions'] = df['Questions'].apply(clean_text)\n",
    "    print(\"Cleaned Questions Column:\")\n",
    "    print(df[['Questions', 'cleaned_questions']].head())\n",
    "else:\n",
    "    print(\"The dataset does not have a 'Questions' column. Available columns are:\", df.columns)\n",
    "    raise KeyError(\"Missing 'Questions' column in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvNlwWd_Xy_0",
    "outputId": "64e93907-35ab-448e-bc5f-cfab6eca1c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to ./output/tokenizer.pkl\n",
      "Padded Sequences:\n",
      "[[  3  40  49 ...   0   0   0]\n",
      " [ 67  40   6 ...   0   0   0]\n",
      " [  3  27 103 ...   0   0   0]\n",
      " ...\n",
      " [  5   2   1 ...   0   0   0]\n",
      " [  3  12  10 ...   0   0   0]\n",
      " [  3  12  10 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the cleaned questions\n",
    "sequences, vocab_size, tokenizer = tokenize_data(df, 'cleaned_questions')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer_path = os.path.join(output_dir, \"tokenizer.pkl\")\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "# Pad the sequences\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Padded Sequences:\")\n",
    "print(padded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djvX0SwzX0tF",
    "outputId": "4781c437-14ed-45b1-d82b-1b56898070cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels: [46 45 69 90 86]\n",
      "Number of Classes: 97\n"
     ]
    }
   ],
   "source": [
    "# Encode the answers as labels\n",
    "if 'Answers' in df.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(df['Answers'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(\"Encoded Labels:\", encoded_labels[:5])\n",
    "    print(\"Number of Classes:\", num_classes)\n",
    "else:\n",
    "    print(\"The dataset does not have an 'Answers' column. Available columns are:\", df.columns)\n",
    "    raise KeyError(\"Missing 'Answers' column in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMcBf9CGX3lx",
    "outputId": "3a4f5e45-1c3d-42f4-80db-67b283142a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 478ms/step - accuracy: 0.0000e+00 - loss: 4.5822 - val_accuracy: 0.0000e+00 - val_loss: 4.5886\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.0169 - loss: 4.5712 - val_accuracy: 0.0000e+00 - val_loss: 4.6015\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0000e+00 - loss: 4.5591 - val_accuracy: 0.0000e+00 - val_loss: 4.6197\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0247 - loss: 4.5492 - val_accuracy: 0.0000e+00 - val_loss: 4.6507\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0286 - loss: 4.5420 - val_accuracy: 0.0000e+00 - val_loss: 4.7028\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0286 - loss: 4.5356 - val_accuracy: 0.0000e+00 - val_loss: 4.7597\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0208 - loss: 4.5344 - val_accuracy: 0.0000e+00 - val_loss: 4.7840\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0273 - loss: 4.5032 - val_accuracy: 0.0000e+00 - val_loss: 4.7924\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0364 - loss: 4.4814 - val_accuracy: 0.0000e+00 - val_loss: 4.8210\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.0468 - loss: 4.4913 - val_accuracy: 0.0000e+00 - val_loss: 4.8654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./output/model.h5\n"
     ]
    }
   ],
   "source": [
    "# Build a simple neural network model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(padded_sequences, encoded_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(output_dir, \"model.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBH-mvcQYBfM",
    "outputId": "b379e2fc-62f6-40b2-ed1b-1900dbe47e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0311 - loss: 4.5038\n",
      "Model Loss: 4.536472320556641\n",
      "Model Accuracy: 0.030927835032343864\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_sequences, encoded_labels)\n",
    "print(f\"Model Loss: {loss}\")\n",
    "print(f\"Model Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERaEwIzFYMHy",
    "outputId": "69b603cf-9e75-4785-cb15-2dae29f3ad7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved at ./output/tokenizer.pkl\n",
      "Model saved at ./output/chatbot_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved at {tokenizer_path}\")\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(output_dir, \"chatbot_model.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved at {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlA-q1FqYOve",
    "outputId": "5128da91-59f1-4d0a-b8f1-f412d93ddda1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "with open(tokenizer_path, 'rb') as f:\n",
    "    loaded_tokenizer = pickle.load(f)\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "niTWQogBYRzq"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess user input and predict the class\n",
    "def predict_answer(question):\n",
    "    # Clean and tokenize the input question\n",
    "    cleaned_question = clean_text(question)\n",
    "    sequence = loaded_tokenizer.texts_to_sequences([cleaned_question])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
    "\n",
    "    # Predict the response class\n",
    "    prediction = loaded_model.predict(padded_sequence)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "    # Map the predicted label back to the original answer\n",
    "    response = label_encoder.inverse_transform([predicted_label])[0]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__GBaVMXYUbe",
    "outputId": "0b6f9dff-4488-4b8b-8537-781298716cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: \"I feel stressed all the time. What should I do?\"\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "Chatbot: It may be tempting to try to block out the world altogether to avoid bad news, but it's important to keep yourself informed. We all have to step up during a pandemic because we all have a part to play in reducing the spread of the virus. It's important that you know what must be done and how you should do it. This is important for the health of your neighbours and your own mental health, and taking action can help counter difficult feelings like hopelessness and despair. \n",
      " One study from people in China found that people who had reliable up-to-date information about the coronavirus and COVID-19 illness and accurate instructions on how they should act (such as instructions around hand-washing and wearing a mask) felt more resilient and felt better able to handle the virus. People who received good, accurate information reported lower levels of stress, anxiety, and depression. This research is available for free at www.mdpi.com/1660-4601/17/5/1729. \n",
      " Of course, it's okay to set limits. Staying informed does not mean that you have to follow the news all day. Check in a few times a day, sticking to trusted sources and media outlets. While social media can be a great way to keep in touch with family and friends, social media can also amplify bad advice, vague or untrue stories, and other unhelpful information. Be sure to use good critical thinking skills.\n",
      "You: \"Where can I find mental health support?\"\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Chatbot: It may be tempting to try to block out the world altogether to avoid bad news, but it's important to keep yourself informed. We all have to step up during a pandemic because we all have a part to play in reducing the spread of the virus. It's important that you know what must be done and how you should do it. This is important for the health of your neighbours and your own mental health, and taking action can help counter difficult feelings like hopelessness and despair. \n",
      " One study from people in China found that people who had reliable up-to-date information about the coronavirus and COVID-19 illness and accurate instructions on how they should act (such as instructions around hand-washing and wearing a mask) felt more resilient and felt better able to handle the virus. People who received good, accurate information reported lower levels of stress, anxiety, and depression. This research is available for free at www.mdpi.com/1660-4601/17/5/1729. \n",
      " Of course, it's okay to set limits. Staying informed does not mean that you have to follow the news all day. Check in a few times a day, sticking to trusted sources and media outlets. While social media can be a great way to keep in touch with family and friends, social media can also amplify bad advice, vague or untrue stories, and other unhelpful information. Be sure to use good critical thinking skills.\n",
      "You: \"What treatments are available for anxiety?\"\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Chatbot: It may be tempting to try to block out the world altogether to avoid bad news, but it's important to keep yourself informed. We all have to step up during a pandemic because we all have a part to play in reducing the spread of the virus. It's important that you know what must be done and how you should do it. This is important for the health of your neighbours and your own mental health, and taking action can help counter difficult feelings like hopelessness and despair. \n",
      " One study from people in China found that people who had reliable up-to-date information about the coronavirus and COVID-19 illness and accurate instructions on how they should act (such as instructions around hand-washing and wearing a mask) felt more resilient and felt better able to handle the virus. People who received good, accurate information reported lower levels of stress, anxiety, and depression. This research is available for free at www.mdpi.com/1660-4601/17/5/1729. \n",
      " Of course, it's okay to set limits. Staying informed does not mean that you have to follow the news all day. Check in a few times a day, sticking to trusted sources and media outlets. While social media can be a great way to keep in touch with family and friends, social media can also amplify bad advice, vague or untrue stories, and other unhelpful information. Be sure to use good critical thinking skills.\n",
      "You: exit\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot with example inputs\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = predict_answer(user_input)\n",
    "    print(f\"Chatbot: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
