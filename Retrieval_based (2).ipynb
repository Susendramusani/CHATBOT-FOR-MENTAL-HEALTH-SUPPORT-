{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "import json\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Embedding, Dense, Flatten, Conv1D, MaxPooling1D, SimpleRNN, GRU, LSTM, Input,\n",
        "                                      TimeDistributed, Dropout, Bidirectional)\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "-DjieXLqVq7J"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the requirements.txt file\n",
        "print(\"Please upload the 'requirements.txt' file.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Install dependencies from the uploaded requirements file\n",
        "for file_name in uploaded.keys():\n",
        "    if file_name.endswith('.txt'):\n",
        "        !pip install -r \"{file_name}\"\n",
        "\n",
        "# Ensure NLTK resources are available\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Gx2VoOAV_vM",
        "outputId": "13ba052a-1a68-4b2d-ae0d-a07809999c56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the 'requirements.txt' file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f278d8b7-87b7-4494-9780-f7168b9e1a32\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f278d8b7-87b7-4494-9780-f7168b9e1a32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements.txt to requirements (1).txt\n",
            "Collecting absl-py==2.1.0 (from -r requirements (1).txt (line 1))\n",
            "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 2)) (1.6.3)\n",
            "Collecting cachetools==5.3.2 (from -r requirements (1).txt (line 3))\n",
            "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting certifi==2023.11.17 (from -r requirements (1).txt (line 4))\n",
            "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting charset-normalizer==3.3.2 (from -r requirements (1).txt (line 5))\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 6)) (8.1.7)\n",
            "Collecting contourpy==1.1.1 (from -r requirements (1).txt (line 7))\n",
            "  Using cached contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 8)) (0.12.1)\n",
            "Collecting flatbuffers==23.5.26 (from -r requirements (1).txt (line 9))\n",
            "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting fonttools==4.47.2 (from -r requirements (1).txt (line 10))\n",
            "  Using cached fonttools-4.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (157 kB)\n",
            "Collecting gast==0.4.0 (from -r requirements (1).txt (line 11))\n",
            "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-auth==2.27.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 12)) (2.27.0)\n",
            "Collecting google-auth-oauthlib==1.0.0 (from -r requirements (1).txt (line 13))\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 14)) (0.2.0)\n",
            "Collecting grpcio==1.60.0 (from -r requirements (1).txt (line 15))\n",
            "  Using cached grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting h5py==3.10.0 (from -r requirements (1).txt (line 16))\n",
            "  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting idna==3.6 (from -r requirements (1).txt (line 17))\n",
            "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting importlib-resources==6.1.1 (from -r requirements (1).txt (line 18))\n",
            "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting joblib==1.3.2 (from -r requirements (1).txt (line 19))\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keras==2.13.1 (from -r requirements (1).txt (line 20))\n",
            "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting kiwisolver==1.4.5 (from -r requirements (1).txt (line 21))\n",
            "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting libclang==16.0.6 (from -r requirements (1).txt (line 22))\n",
            "  Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting Markdown==3.5.2 (from -r requirements (1).txt (line 23))\n",
            "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting MarkupSafe==2.1.4 (from -r requirements (1).txt (line 24))\n",
            "  Using cached MarkupSafe-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.7.4 (from -r requirements (1).txt (line 25))\n",
            "  Using cached matplotlib-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting nltk==3.8.1 (from -r requirements (1).txt (line 26))\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting numpy==1.24.3 (from -r requirements (1).txt (line 27))\n",
            "  Using cached numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 28)) (3.2.2)\n",
            "Collecting opt-einsum==3.3.0 (from -r requirements (1).txt (line 29))\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pandas==2.0.3 (from -r requirements (1).txt (line 30))\n",
            "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pillow==10.2.0 (from -r requirements (1).txt (line 31))\n",
            "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting protobuf==4.25.2 (from -r requirements (1).txt (line 32))\n",
            "  Using cached protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pyasn1==0.5.1 (from -r requirements (1).txt (line 33))\n",
            "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pyasn1-modules==0.3.0 (from -r requirements (1).txt (line 34))\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pyparsing==3.1.1 (from -r requirements (1).txt (line 35))\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pytz==2023.3.post1 (from -r requirements (1).txt (line 36))\n",
            "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting regex==2023.12.25 (from -r requirements (1).txt (line 37))\n",
            "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests==2.31.0 (from -r requirements (1).txt (line 38))\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: requests-oauthlib==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 39)) (1.3.1)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 40)) (4.9)\n",
            "Collecting tensorboard==2.13.0 (from -r requirements (1).txt (line 41))\n",
            "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements (1).txt (line 42)) (0.7.2)\n",
            "Collecting tensorflow==2.13.0 (from -r requirements (1).txt (line 43))\n",
            "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tensorflow-estimator==2.13.0 (from -r requirements (1).txt (line 44))\n",
            "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-macos==2.13.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-macos==2.13.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload dataset\n",
        "print(\"Please upload the dataset file. \")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "for file_name in uploaded.keys():\n",
        "    if file_name.endswith('.csv'):\n",
        "        df = pd.read_csv(file_name)\n",
        "    elif file_name.endswith('.json'):\n",
        "        with open(file_name, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            df = pd.DataFrame(data)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "UEY13wFCWCKi",
        "outputId": "a840a94a-83de-4305-e109-e8c00acae651"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the dataset file. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9609c293-a78c-4eb7-8413-719b053aa892\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9609c293-a78c-4eb7-8413-719b053aa892\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mentalhealth.csv to mentalhealth (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Question_ID                                          Questions  \\\n",
              "0      1590140        What does it mean to have a mental illness?   \n",
              "1      2110618                    Who does mental illness affect?   \n",
              "2      9434130  What are some of the warning signs of mental i...   \n",
              "3      7657263            Can people with mental illness recover?   \n",
              "4      1619387  What should I do if I know someone who appears...   \n",
              "\n",
              "                                             Answers  \n",
              "0  Mental illnesses are health conditions that di...  \n",
              "1  Mental illness does can affect anyone, regardl...  \n",
              "2  Symptoms of mental health disorders vary depen...  \n",
              "3  When healing from mental illness, early identi...  \n",
              "4  We encourage those with symptoms to talk to th...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad6c17f4-3d47-408f-bb08-a3c0ea633e05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question_ID</th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1590140</td>\n",
              "      <td>What does it mean to have a mental illness?</td>\n",
              "      <td>Mental illnesses are health conditions that di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2110618</td>\n",
              "      <td>Who does mental illness affect?</td>\n",
              "      <td>Mental illness does can affect anyone, regardl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9434130</td>\n",
              "      <td>What are some of the warning signs of mental i...</td>\n",
              "      <td>Symptoms of mental health disorders vary depen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7657263</td>\n",
              "      <td>Can people with mental illness recover?</td>\n",
              "      <td>When healing from mental illness, early identi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1619387</td>\n",
              "      <td>What should I do if I know someone who appears...</td>\n",
              "      <td>We encourage those with symptoms to talk to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad6c17f4-3d47-408f-bb08-a3c0ea633e05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad6c17f4-3d47-408f-bb08-a3c0ea633e05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad6c17f4-3d47-408f-bb08-a3c0ea633e05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2241f48f-a39d-4132-92a6-7ef765717560\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2241f48f-a39d-4132-92a6-7ef765717560')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2241f48f-a39d-4132-92a6-7ef765717560 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"Question_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2707777,\n        \"min\": 1030153,\n        \"max\": 9679704,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          1043721,\n          4134858,\n          7807643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"I received a diagnosis but I don\\u2019t think it\\u2019s right. What can I do?\",\n          \"How can I manage grief?\",\n          \"If cannabis is dangerous, why are we legalizing it?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"If possible, bring up your concerns with the professional who provided the diagnosis. That way, the professional can answer your questions and you can better understand their decision. \\n If that doesn\\u2019t resolve the situation or a follow-up appointment isn\\u2019t possible, you can ask for a second opinion. A second opinion is an assessment from a different professional. This can give you better understanding of what\\u2019s going on and what to do about it. Second opinions are common when it comes to major health decisions\\u2014you won\\u2019t hurt anyone\\u2019s feelings and your doctor will try to accommodate reasonable requests for a second opinion. Talk to your family doctor (or go to a walk-in clinic) to discuss your options and get a referral to a different program or health professional, if needed. \\n For more how to get a second opinion, see HealthLinkBC\\u2019s factsheet at www.healthlinkbc.ca. \\n For general tips on managing a diagnosis of a mental illness and working well with health care professionals, see HeretoHelp\\u2019s Managing a Mental Illness series.\",\n          \"While a lot of people think of grief in terms of losing a person or pet, grief can come up whenever you lose something important. This includes: \\n Losing security, like losing your job or wondering how long you'll be able to pay rent \\n Losing stability or routine, like finding yourself working from home or navigating childcare closures \\n Losing your sense of safety, like fearing you or someone you love might end up with COVID-19 \\n Losing your social relationships, like missing time with family and friends now that everyone must practice physical distancing or self-isolation \\n Losing hope for the future, like feeling that life will never go back to normal \\n Losing important goals, like finding your classes, sports competitions, or performances are cancelled for the foreseeable future \\n Losing important milestone celebrations like graduation ceremonies and weddings \\n Grief bring up complicated feelings. You might feel sad, angry, frustrated, fearful, or hopeless. You may have a hard time eating or sleeping, or feel very tense. You may feel overwhelmed and tired. You may wonder if life will ever feel normal again. \\n Everyone grieves in their own way and their own time. Here are some strategies to try as you navigate your own journey. \\n Acknowledge and express your feelings in a healthy way. Give your feelings a name and find healthy ways to express them, such as by talking with a friend, writing in a journal, or making art. \\n Give yourself as much time as you need. Grief follows its own schedule. Give yourself permission to use this time to take care of your well-being. Let go of expectations, tasks, or other obligations that can wait. \\n Seek support. Grief can feel very isolating, even though a lot of people are experiencing some sort of loss right now. Reach out to friends or family and share your feelings. Look for ways to help and support each other. \\n Take care of yourself. Ignoring health and well-being can make difficult experiences feel worse. Eat as well as you can, try to get enough sleep, spend time outside if it's safe for you to do so, and exercise regularly. Think about self-care activities or strategies that have helped you cope with challenging situations in the past and make time for those activities. \\n Know that feelings of grief will pass. Grief may feel intense at times, but those feelings will become more manageable over time and will eventually pass. \\n Connect with a mental health professional if you're having a hard time. If you're having a hard time getting through the day, coping in unhealthy ways, or having a hard time managing difficult thoughts or feelings, it's a good idea to seek help from a professional like a psychologist or counsellor\\u2014many now offer online or phone appointments. To find help: \\n For everyone \\n BC Psychological Association: Find a Registered Psychologist at www.psychologists.bc.ca/find_psychologist \\n BC Association of Clinical Counsellors: Find a Registered Clinical Counsellor at bc-counsellors.org \\n BC Mental Health Support Line: call 310-6789 (no area code) for to learn about services in your area or just to talk with someone right now \\n For young people \\n Kids Help Phone: Talk to a counsellor at 1-800-668-6868 or chat at kidshelpphone.ca (available 24/7) \\n Foundry: Contact your local Foundry office at foundrybc.ca for Foundy Virtual and information about local resources (for youth ages 12-24) \\n Youth in BC: Chat with a crisis line responder at youthinbc.com (available every day from noon \\u2013 1:00am) \\n That Discomfort You're Feeling Is Grief in Harvard Business Review at hbr.org/2020/03/that-discomfort-youre-feeling-is-grief \\n Grieving from the Canadian Mental Health Association at cmha.ca/documents/grieving \\n Coping with Grief and Loss from Mind Your Mind at mindyourmind.ca/wellness/coping-grief-and-loss\",\n          \"Cannabis smoke, for example, contains cancer-causing toxins. However, the risk of developing some cancers (e.g., mouth, tongue and lung) is less for cannabis smokers than tobacco smokers, partly because they tend to smoke less than tobacco users. And, while all drugs have an effect on the brain, the particular properties of the drug influence the level of risk of harmful consequences. The negative effects of cannabis on the brain, for example, seem to be less than the effects of some substances such as alcohol. \\n Legalizing cannabis provides an opportunity to put in place regulations to minimize potential harms. The danger of buying and using any illegal drug is that we can never know for sure what exactly is in it. Cannabis is legal in Canada as of October 17, 2018. Adults (over age 19 in BC) are now permitted to possess up to 30 grams of cannabis in public. Cannabis is regulated by the Province of British Columbia and will be sold through the Liquor Distribution Branch. Cannabis will be tested for quality. \\n When drugs are produced and obtained inside a regulated system, it is possible for us to know about the contents and dosage of what we are taking. This helps us manage the risks. However, it is likely that cannabis will still be available outside the government system. It is important to know that the quality of cannabis obtained from a dealer or a friend is unknown and may contain contaminants like mold, mildew, or fillers that may be toxic. \\n The legalization of cannabis also provides us with openings to engage in honest and thoughtful discussions about drug use with our families and communities. When dealing with complex issues, like cannabis policy, no one has all the answers. But as community members, we all have thoughts, feelings and experiences around drugs and drug use to share with each other. Engaging together to explore and share ideas will help us discover how to manage use, as individuals and communities, in ways that maximize benefit and minimize harm. \\n The Canadian Institute for Substance Use Research, formerly CARBC, is a member of the BC Partners for Mental Health and Addictions Information. The institute is dedicated to the study of substance use in support of community-wide efforts aimed at providing all people with access to healthier lives, whether using substances or not. For more, visit www.cisur.ca.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define the clean_text function\n",
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters, numbers, and extra spaces\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Iy9QnUHOcQBj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamically check for the correct column name\n",
        "if 'Questions' in df.columns:\n",
        "    df['cleaned_questions'] = df['Questions'].apply(clean_text)\n",
        "    print(\"Cleaned Questions Column:\")\n",
        "    print(df[['Questions', 'cleaned_questions']].head())\n",
        "else:\n",
        "    print(\"The dataset does not have a 'Questions' column. Available columns are:\", df.columns)\n",
        "    raise KeyError(\"Missing 'Questions' column in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UVUrXPdWEhN",
        "outputId": "334a6ec8-c896-466f-9ec7-e3aa72283eaf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Questions Column:\n",
            "                                           Questions  \\\n",
            "0        What does it mean to have a mental illness?   \n",
            "1                    Who does mental illness affect?   \n",
            "2  What are some of the warning signs of mental i...   \n",
            "3            Can people with mental illness recover?   \n",
            "4  What should I do if I know someone who appears...   \n",
            "\n",
            "                                   cleaned_questions  \n",
            "0         what does it mean to have a mental illness  \n",
            "1                     who does mental illness affect  \n",
            "2  what are some of the warning signs of mental i...  \n",
            "3             can people with mental illness recover  \n",
            "4  what should i do if i know someone who appears...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "\n",
        "# Define the tokenize_data function\n",
        "def tokenize_data(df, column_name, num_words=10000):\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(df[column_name])\n",
        "    sequences = tokenizer.texts_to_sequences(df[column_name])\n",
        "    vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding token\n",
        "    return sequences, vocab_size, tokenizer\n",
        "\n",
        "# Tokenize the cleaned questions first\n",
        "sequences, vocab_size, tokenizer = tokenize_data(df, 'cleaned_questions')\n",
        "\n",
        "# Now you can save the tokenizer because it has been defined\n",
        "output_dir = \"./tokenizer_output\"  # Directory to save the tokenizer\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "tokenizer_path = os.path.join(output_dir, \"tokenizer.pkl\")\n",
        "with open(tokenizer_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(f\"Tokenizer saved to {tokenizer_path}\")\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "print(\"Padded Sequences:\")\n",
        "print(padded_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIrCsA56fBFW",
        "outputId": "55560648-38ff-4d17-9ba4-803a9f972b11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer saved to ./tokenizer_output/tokenizer.pkl\n",
            "Padded Sequences:\n",
            "[[  4  41  50 ...   0   0   0]\n",
            " [ 68  41   7 ...   0   0   0]\n",
            " [  4  28 104 ...   0   0   0]\n",
            " ...\n",
            " [  6   3   2 ...   0   0   0]\n",
            " [  4  13  11 ...   0   0   0]\n",
            " [  4  13  11 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the answers as labels\n",
        "if 'Answers' in df.columns:\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(df['Answers'])\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    print(\"Encoded Labels:\", encoded_labels[:5])\n",
        "    print(\"Number of Classes:\", num_classes)\n",
        "else:\n",
        "    print(\"The dataset does not have an 'Answers' column. Available columns are:\", df.columns)\n",
        "    raise KeyError(\"Missing 'Answers' column in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djvX0SwzX0tF",
        "outputId": "85e1d681-a041-479e-b72c-d8af84354444"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Labels: [46 45 69 90 86]\n",
            "Number of Classes: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple neural network model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(padded_sequences, encoded_labels, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Save the model\n",
        "model_path = os.path.join(output_dir, \"model.h5\")\n",
        "model.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMcBf9CGX3lx",
        "outputId": "2729bb35-c6a7-4019-8b87-f255d7642de2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 253ms/step - accuracy: 0.0104 - loss: 4.5765 - val_accuracy: 0.0000e+00 - val_loss: 4.5998\n",
            "Epoch 2/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0858 - loss: 4.5592 - val_accuracy: 0.0000e+00 - val_loss: 4.6308\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0000e+00 - loss: 4.5633 - val_accuracy: 0.0000e+00 - val_loss: 4.6692\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0247 - loss: 4.5455 - val_accuracy: 0.0000e+00 - val_loss: 4.7030\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0208 - loss: 4.5121 - val_accuracy: 0.0000e+00 - val_loss: 4.7559\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0572 - loss: 4.4966 - val_accuracy: 0.0000e+00 - val_loss: 4.8226\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.0065 - loss: 4.5443 - val_accuracy: 0.0000e+00 - val_loss: 4.8712\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0286 - loss: 4.5333 - val_accuracy: 0.0000e+00 - val_loss: 4.8908\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0468 - loss: 4.4801 - val_accuracy: 0.0000e+00 - val_loss: 4.9324\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0390 - loss: 4.4908 - val_accuracy: 0.0000e+00 - val_loss: 4.9856\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0065 - loss: 4.4613 - val_accuracy: 0.0000e+00 - val_loss: 5.0993\n",
            "Epoch 12/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0286 - loss: 4.4232 - val_accuracy: 0.0000e+00 - val_loss: 5.2093\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0676 - loss: 4.3938 - val_accuracy: 0.0000e+00 - val_loss: 5.2405\n",
            "Epoch 14/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0416 - loss: 4.4018 - val_accuracy: 0.0000e+00 - val_loss: 5.2700\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0572 - loss: 4.3380 - val_accuracy: 0.0000e+00 - val_loss: 5.3437\n",
            "Epoch 16/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0468 - loss: 4.3079 - val_accuracy: 0.0000e+00 - val_loss: 5.4281\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0533 - loss: 4.3178 - val_accuracy: 0.0000e+00 - val_loss: 5.5148\n",
            "Epoch 18/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0182 - loss: 4.2523 - val_accuracy: 0.0000e+00 - val_loss: 5.6024\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0390 - loss: 4.2182 - val_accuracy: 0.0000e+00 - val_loss: 5.6591\n",
            "Epoch 20/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0650 - loss: 4.1073 - val_accuracy: 0.0000e+00 - val_loss: 5.8998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./tokenizer_output/model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_sequences, encoded_labels)\n",
        "print(f\"Model Loss: {loss}\")\n",
        "print(f\"Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBH-mvcQYBfM",
        "outputId": "668d6a7a-2ef2-4b63-e585-3e960627def9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0809 - loss: 4.2199 \n",
            "Model Loss: 4.343997955322266\n",
            "Model Accuracy: 0.09278350323438644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the tokenizer\n",
        "with open(tokenizer_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(f\"Tokenizer saved at {tokenizer_path}\")\n",
        "\n",
        "# Save the model\n",
        "model_path = os.path.join(output_dir, \"chatbot_model.h5\")\n",
        "model.save(model_path)\n",
        "print(f\"Model saved at {model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERaEwIzFYMHy",
        "outputId": "bba4eb4b-6794-4700-df41-b89200801de9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer saved at ./tokenizer_output/tokenizer.pkl\n",
            "Model saved at ./tokenizer_output/chatbot_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "with open(tokenizer_path, 'rb') as f:\n",
        "    loaded_tokenizer = pickle.load(f)\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = load_model(model_path)\n",
        "print(\"Model and tokenizer loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlA-q1FqYOve",
        "outputId": "caf97880-f5e1-4275-fcec-e9c8d185c3ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess user input and predict the class\n",
        "def predict_answer(question):\n",
        "    # Clean and tokenize the input question\n",
        "    cleaned_question = clean_text(question)\n",
        "    sequence = loaded_tokenizer.texts_to_sequences([cleaned_question])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Predict the response class\n",
        "    prediction = loaded_model.predict(padded_sequence)\n",
        "    predicted_label = np.argmax(prediction)\n",
        "\n",
        "    # Map the predicted label back to the original answer\n",
        "    response = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "niTWQogBYRzq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the chatbot with example inputs\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['exit', 'quit']:\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = predict_answer(user_input)\n",
        "    print(f\"Chatbot: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__GBaVMXYUbe",
        "outputId": "7965a5e8-2d6b-40aa-b2df-f8906324cfaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: What does it mean to have a mental illness?\t\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
            "Chatbot: Similar to a medical advance directive or a health care power of attorney, a psychiatric advance directive is a legal document completed in a time of wellness that provides instructions regarding treatment or services one wishes to have or not have during a mental health crisis, and may help influence his or her care.\n",
            "You: Who does mental illness affect?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Chatbot: There are a lot of things you can't control. You can't control what happens next, how governments respond, or how your neighbours react to the pandemic. What you can do is make a plan and decide how you'll manage the things you do control, like your ability to stay safe, follow public health measures, stay connected with loved ones, and take care of your mental and physical health. \n",
            " Events like a pandemic change a lot over time, and that uncertainty can add to fear and stress. The truth is that we don't know what will happen nextbut that doesn't mean we're all helpless. You can do a lot. You can: \n",
            " Map out a daily schedule, including times you can connect with loved ones online or by phone \n",
            " Plan out daily tasks and goals \n",
            " Give yourself a schedule to look up current information \n",
            " Make sure you have 14 days of healthy food and household supplies at home \n",
            " Keep medications on hand and talk to your doctor for advice if you're at increased risk \n",
            " Educate yourself on public health measures and figure out how you'll follow those instructions \n",
            " Figure out how you'll manage increased childcare demands, working for home, or other changes to your usual routine \n",
            " Determine if you'll need financial supports like the Canada Emergency Response Benefit or BC Temporary Rent Supplement if your job is affected by COVID-19. If you anticipate a need, you can find application instructions and gather any documents or other pieces of information ahead of time \n",
            " Figure out how you'll manage times when you feel overwhelmed or hopeless, like calming activities, the number for a local support or crisis line, a video chat with a loved one, or a way to connect with your mental health care provider \n",
            " Look for local support organizations, neighbourhood groups, or mutual aid groups if you need extra help or support or would like to help others in your community \n",
            " Some planning will be straightforward, but you may also encounter situations or times when it's harder to see a solution or good plan of action. This is a great time to practice problem-solving skills. Problem-solving is a method that helps you break down a complicated situation into manageable pieces, look for realistic and unbiased information, brainstorm possible solutions, and test the solutions that you think might work well. Problem-solving is a helpful skill no matter what else is going on in the world, and it's an empowering, methodical approach when you might otherwise feel overwhelmed or lost. \n",
            " Check out the following resources for more information about problem-solving: \n",
            " Wellness Module 4: Problem-Solving: www.heretohelp.bc.ca/wellness-module/wellness-module-4-problem-solving \n",
            " Problem-solving worksheet from Anxiety Canada: www.anxietycanada.com/sites/default/files/ProblemSolving.pdf \n",
            " Effective Problem-Solving in The Antidepressant Skills Workbook: psychhealthandsafety.org/asw\n",
            "You: Can people with mental illness recover?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Chatbot: There are a lot of things you can't control. You can't control what happens next, how governments respond, or how your neighbours react to the pandemic. What you can do is make a plan and decide how you'll manage the things you do control, like your ability to stay safe, follow public health measures, stay connected with loved ones, and take care of your mental and physical health. \n",
            " Events like a pandemic change a lot over time, and that uncertainty can add to fear and stress. The truth is that we don't know what will happen nextbut that doesn't mean we're all helpless. You can do a lot. You can: \n",
            " Map out a daily schedule, including times you can connect with loved ones online or by phone \n",
            " Plan out daily tasks and goals \n",
            " Give yourself a schedule to look up current information \n",
            " Make sure you have 14 days of healthy food and household supplies at home \n",
            " Keep medications on hand and talk to your doctor for advice if you're at increased risk \n",
            " Educate yourself on public health measures and figure out how you'll follow those instructions \n",
            " Figure out how you'll manage increased childcare demands, working for home, or other changes to your usual routine \n",
            " Determine if you'll need financial supports like the Canada Emergency Response Benefit or BC Temporary Rent Supplement if your job is affected by COVID-19. If you anticipate a need, you can find application instructions and gather any documents or other pieces of information ahead of time \n",
            " Figure out how you'll manage times when you feel overwhelmed or hopeless, like calming activities, the number for a local support or crisis line, a video chat with a loved one, or a way to connect with your mental health care provider \n",
            " Look for local support organizations, neighbourhood groups, or mutual aid groups if you need extra help or support or would like to help others in your community \n",
            " Some planning will be straightforward, but you may also encounter situations or times when it's harder to see a solution or good plan of action. This is a great time to practice problem-solving skills. Problem-solving is a method that helps you break down a complicated situation into manageable pieces, look for realistic and unbiased information, brainstorm possible solutions, and test the solutions that you think might work well. Problem-solving is a helpful skill no matter what else is going on in the world, and it's an empowering, methodical approach when you might otherwise feel overwhelmed or lost. \n",
            " Check out the following resources for more information about problem-solving: \n",
            " Wellness Module 4: Problem-Solving: www.heretohelp.bc.ca/wellness-module/wellness-module-4-problem-solving \n",
            " Problem-solving worksheet from Anxiety Canada: www.anxietycanada.com/sites/default/files/ProblemSolving.pdf \n",
            " Effective Problem-Solving in The Antidepressant Skills Workbook: psychhealthandsafety.org/asw\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}